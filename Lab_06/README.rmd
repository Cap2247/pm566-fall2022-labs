---
title: "Lab 06"
author: "CP"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Read in the data
First download and then read in with data.table:fread()

```{r read-data, cache=TRUE}
if (!file.exists("mtsamples.csv"))
download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv", "mtsamples.csv", method="libcurl", timeout = 60)
```

```{r}
mts <- read.csv("mtsamples.csv")
```

```{r library}
library(tidytext)
library(tidyverse)
library(data.table)
library(dplyr)
library(ggplot2)
library(forcats)
```

```{r}
str(mts)

mts <- as_tibble(mts)
```
###Question 1: What specialties do we have?
We can use count() from dplyr to figure out how many different catagories do we have? Are these catagories related? overlapping? evenly distributed?
```{r}
specialties <-mts %>% count(medical_specialty) 
specialties %>% arrange(desc(n))
  
```

```{r}
specialties %>%
  top_n(10) %>%
  ggplot(aes(x = n , y = fct_reorder(medical_specialty, n))) + geom_col()
```
###Question 2 and 3 removal of stop words 
Tokenize the the words in the transcription column
Count the number of times each token appears
Visualize the top 20 most frequent words

```{r}
mts %>%
  unnest_tokens(word, transcription) %>%
  anti_join(stop_words, by = c("word")) %>%
  count(word, sort = TRUE) %>%
  filter(!grepl(pattern = "^[0-9]+$", x = word)) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```
There are many stop words, not specific to medical procedure. Patient is the most frequently used word, and we removed the numbers 

### Question 4
Bonus points if you remove numbers as well

```{r}

```

